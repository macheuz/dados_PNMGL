{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Funcoes utilizadas\n",
    "Criar uma lista de comprimentos de strings em cada célula da coluna especificada\n",
    "comprimentos = [len(str(celula)) for celula in df.iloc[: ,4]]\n",
    "Encontrar o índice da célula com o maior número de caracteres\n",
    "indice_maior = comprimentos.index(max(comprimentos))\n",
    "Extrair a célula com o maior número de caracteres\n",
    "celula_maior = df.iloc[indice_maior][4] df.iloc[: , 4][indice_maior] df.iloc[: , 4].value_counts() celula_maior df.iloc[:,0]\n",
    "index = df.columns.get_loc(‘abcz’)\n",
    "index df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "IDANIMAL = CHAVE UNICA\n",
    "MP = CHAVE UNICA -  Mes parto\n",
    "AP = CHAVE UNICA - -Ano parto\n",
    "\n",
    "LTOT = lactacao total\n",
    "L365 = lactacao em ate 365 dias\n",
    "L305 = lactacao em ate 305 dias\n",
    "DE = Data de Secagem\n",
    "ME = Mes de secagem\n",
    "AE = ANO de Secagem\n",
    "caso o LTOT, L365 e L305, DE, ME e AE sejam iguais ao arquivo old, pode ser descartado"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## conectando no banco de dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"127.0.0.1\",\n",
    "  user=\"root\",\n",
    "  password=\"4d5f0l9k\",\n",
    "  database=\"bioinformatica_new\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retornando toda tabela genealogia_embrapa e genealogia_abcz e tabela criadores do banco de dados para dataframes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sql = f\"WITH tabela_virtual AS (SELECT * FROM genealogia_embrapa) SELECT tv.*, (SELECT registro FROM tabela_virtual AS pai WHERE pai.id_produto = tv.id_touro) AS registro_pai, (SELECT registro FROM tabela_virtual AS mae WHERE mae.id_produto = tv.id_vaca) AS registro_mae FROM tabela_virtual AS tv\"\n",
    "sql1 = \"SELECT * FROM genealogia_abcz\"\n",
    "sql2 = \"SELECT * FROM criadores\"\n",
    "sql3 = \"SELECT * FROM producao_embrapa\"\n",
    "df_genealogia_embrapa = pd.read_sql(sql, mydb)\n",
    "df_genealogia_embrapa=df_genealogia_embrapa.rename(columns={'idanimal': 'IDANIMAL'})\n",
    "df_genealogia_abcz = pd.read_sql(sql1, mydb)\n",
    "df_criadores = pd.read_sql(sql2, mydb)\n",
    "df_producao = pd.read_sql(sql3, mydb)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lendo planilhas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pedigree = pd.read_csv(\"pedrigree - Girolando - 17-02-2023.txt\", encoding='ISO-8859-1')\n",
    "dados_2023 = pd.read_csv(\"PNMGL - Dados girolando - 17-02-23.txt\", encoding='ISO-8859-1')\n",
    "dados_2022 = pd.read_csv(\"PNMGL - Dados_old - 17-02-2023.txt\", encoding='ISO-8859-1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#pedigree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dados_2022"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dados_2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df_genealogia_embrapa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df_genealogia_abcz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df_criadores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df_producao"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criando um dataframe que é a junção dos dois dataframes, dados_2022 e dados_2023, pelas celulas que possuem os mesmos valores nas colunas IDANIMAL, AP, MP, L305, LTOT, L365, ME e AE."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dados_sem_atualizacao_entre_2022_2023 = pd.merge(dados_2023, dados_2022, on=['IDANIMAL', 'AP', 'MP','L305', 'LTOT', 'L365', 'ME', 'AE', 'CAUSA'],suffixes=('', '_drop'))\n",
    "df_dados_sem_atualizacao_entre_2022_2023 = df_dados_sem_atualizacao_entre_2022_2023.drop(df_dados_sem_atualizacao_entre_2022_2023.filter(regex='_drop$').columns, axis=1)\n",
    "df_dados_sem_atualizacao_entre_2022_2023 = df_dados_sem_atualizacao_entre_2022_2023.drop_duplicates()\n",
    "#df_dados_sem_atualizacao_entre_2022_2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criando um dataframe com somente os novos dados inseridos em 2023\n",
    "Esses são os dados que precisam ser inseridos no banco de dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# faz o merge entre os dois dataframes, o dados com os dados repetidos\n",
    "df_merge = pd.merge(dados_2023, df_dados_sem_atualizacao_entre_2022_2023, how='left', indicator=True, suffixes=('', '_drop'))\n",
    "\n",
    "# filtra somente as linhas que estão no dataframe da esquerda\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_merge[df_merge['_merge'] == 'left_only']\n",
    "\n",
    "# remove a coluna \"_merge\"\n",
    "df_dados_novos_para_insercao_no_banco_de_dados.drop('_merge', axis=1, inplace=True)\n",
    "\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop(df_merge.filter(regex='_drop$').columns, axis=1)\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop_duplicates()\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando coluna GS, oriunda do dataframe Pedigree, no dataframe df_dados_novos_para_insercao_no_banco_de_dados\n",
    "inclusão necessária para localizar o animal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_temporaria = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, pedigree[['IDANIMAL', 'gs', 'SEXO']], on=['IDANIMAL'], suffixes=('', '_drop'))\n",
    "df_dados_novos_para_insercao_no_banco_de_dados=df_temporaria\n",
    "df_dados_novos_para_insercao_no_banco_de_dados\n",
    "\n",
    "nome_antigo = 'SEXO'\n",
    "nome_novo = 'sexo'\n",
    "indice_coluna = df_dados_novos_para_insercao_no_banco_de_dados.columns.get_loc(nome_antigo)\n",
    "df_dados_novos_para_insercao_no_banco_de_dados.rename(columns={nome_antigo: nome_novo}, inplace=True)\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criando subtabela com somente as linhas que possuem gs = 0 no dataframe df_dados_novos_para_insercao_no_banco_de_dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_tabela_gs_0 = df_dados_novos_para_insercao_no_banco_de_dados[df_dados_novos_para_insercao_no_banco_de_dados['gs'] == 0]\n",
    "sub_tabela_gs_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando coluna cod_prod, cod_pai e cod_mae, oriundos do dataframe df_genealogia_abcz, na subtabela gs_0 dos animais que sao gs=0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_genealogia_abcz = df_genealogia_abcz.rename(columns={'rgd2': 'RGVACA'})\n",
    "df_temporaria1 = pd.merge(sub_tabela_gs_0, df_genealogia_abcz[['RGVACA', 'cod_prod', 'cod_pai', 'cod_mae']], on=['RGVACA'], how='left', suffixes=('', '_drop'))\n",
    "sub_tabela_gs_0=df_temporaria1\n",
    "sub_tabela_gs_0 = sub_tabela_gs_0.drop_duplicates()\n",
    "sub_tabela_gs_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando codprod, cod_pai, cod_mae no dataframe df_dados_novos_para_insercao_no_banco_de_dados a partir do dataframe sub_tabela_gs_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_temporaria4 = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, sub_tabela_gs_0[['RGVACA', 'cod_prod', 'cod_pai', 'cod_mae', 'IDANIMAL']], on=['RGVACA', 'IDANIMAL'], how='left', suffixes=('', '_drop'))\n",
    "df_dados_novos_para_insercao_no_banco_de_dados=df_temporaria4\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop_duplicates()\n",
    "df_dados_novos_para_insercao_no_banco_de_dados\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criando subtabela com os animais em que o gs da mae = 11"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_tabela_cod_mae_0 = df_dados_novos_para_insercao_no_banco_de_dados[df_dados_novos_para_insercao_no_banco_de_dados['GSMAE'] == 11]\n",
    "#e o cod_mae e nulo\n",
    "sub_tabela_cod_mae_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pegando o cod_prod das maes no dataframe genealogia_abcz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_genealogia_abcz = df_genealogia_abcz.rename(columns={'cod_prod':'cod_prod_mae_gen'})\n",
    "sub_tabela_cod_mae_0 = pd.merge(sub_tabela_cod_mae_0, df_genealogia_abcz[['RGVACA', 'cod_prod_mae_gen']], left_on=['RGMAE'], right_on=['RGVACA'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "sub_tabela_cod_mae_0 = sub_tabela_cod_mae_0.drop_duplicates()\n",
    "sub_tabela_cod_mae_0 = sub_tabela_cod_mae_0.drop(sub_tabela_cod_mae_0.filter(regex='_drop$').columns, axis=1)\n",
    "sub_tabela_cod_mae_0 = sub_tabela_cod_mae_0[sub_tabela_cod_mae_0['_merge'] == 'both'].drop(columns='_merge')\n",
    "sub_tabela_cod_mae_0\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando o cod_prod_mae_gen das maes no dataframe df_dados_novos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_temporaria5 = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, sub_tabela_cod_mae_0[['RGMAE', 'cod_prod_mae_gen']], left_on=['RGMAE'], right_on=['RGMAE'], how='left', suffixes=('', '_drop'))\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados=df_temporaria4\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop_duplicates()\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados\n",
    "df_temporaria5 = df_temporaria5.drop_duplicates()\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_temporaria5\n",
    "df_dados_novos_para_insercao_no_banco_de_dados\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criando subtabela em que o gs do pai = 11 e que os 3 primeiros caracteres do rgpai sao letras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_tabela_cod_pai_0 = df_dados_novos_para_insercao_no_banco_de_dados[df_dados_novos_para_insercao_no_banco_de_dados['GSPAI'] == 11]\n",
    "#e o cod_mae e nulo\n",
    "sub_tabela_cod_pai_0\n",
    "# selecionar apenas as linhas que começam com letras\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0[sub_tabela_cod_pai_0['RGPAI'].apply(lambda x: bool(re.match(r'^[a-zA-Z]{3}', x)))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pegando o cod_prod dos pais no dataframe genealogia_abcz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_genealogia_abcz = df_genealogia_abcz.rename(columns={'cod_prod_mae_gen':'cod_prod_pai_gen'})\n",
    "sub_tabela_cod_pai_0 = pd.merge(sub_tabela_cod_pai_0, df_genealogia_abcz[['RGVACA', 'cod_prod_pai_gen']], left_on=['RGPAI'], right_on=['RGVACA'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0.drop_duplicates()\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0.drop(sub_tabela_cod_pai_0.filter(regex='_drop$').columns, axis=1)\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0[sub_tabela_cod_pai_0['_merge'] == 'both'].drop(columns='_merge')\n",
    "sub_tabela_cod_pai_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando o cod_prod_pai_gen dos pais no dataframe df_dados_novos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_temporaria6 = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, sub_tabela_cod_pai_0[['RGPAI', 'cod_prod_pai_gen']], left_on=['RGPAI'], right_on=['RGPAI'], how='left', suffixes=('', '_drop'))\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados=df_temporaria5\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop_duplicates()\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop(df_dados_novos_para_insercao_no_banco_de_dados.filter(regex='_drop$').columns, axis=1)\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados\n",
    "df_temporaria6 = df_temporaria6.drop_duplicates()\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_temporaria6\n",
    "df_dados_novos_para_insercao_no_banco_de_dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pegando valores das colunas cod_prod_pai_gen e cod_prod_mae_gen e atualizando colunas  cod_pai e cod_mae no DF_DADOS_NOVOS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_temporaria6 = df_temporaria5\n",
    "df_dados_novos_para_insercao_no_banco_de_dados['cod_pai'].fillna(df_dados_novos_para_insercao_no_banco_de_dados['cod_prod_pai_gen'], inplace=True)\n",
    "df_dados_novos_para_insercao_no_banco_de_dados['cod_mae'].fillna(df_dados_novos_para_insercao_no_banco_de_dados['cod_prod_mae_gen'], inplace=True)\n",
    "#Dando drop nas colunas antigas\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop(columns='cod_prod_pai_gen')\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop(columns='cod_prod_mae_gen')\n",
    "df_dados_novos_para_insercao_no_banco_de_dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criando subtabela em que o gs do pai = 11 mas os 3 primeiros caracteres do rgpai nao sao letras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_tabela_cod_pai_0 = df_dados_novos_para_insercao_no_banco_de_dados[df_dados_novos_para_insercao_no_banco_de_dados['GSPAI'] == 11]\n",
    "#e o cod_mae e nulo\n",
    "sub_tabela_cod_pai_0\n",
    "# selecionar apenas as linhas que NÃO começam com letras\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0[~sub_tabela_cod_pai_0['nome'].apply(lambda x: bool(re.match(r'^[a-zA-Z]{3}', x)))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pegando cod_prod_pai no genealogia_abcz dos animais em que o registro nao comeca com 3 letras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#criando coluna com os 10 caracteres do nome\n",
    "sub_tabela_cod_pai_0['nome10caracteres'] = sub_tabela_cod_pai_0['nome'].str.slice(start=0, stop=11)\n",
    "df_genealogia_abcz['nome10caracteres'] = df_genealogia_abcz['nomea'].str.slice(start=0, stop=11)\n",
    "#removendo os espacos em branco das celulas\n",
    "sub_tabela_cod_pai_0['nome10caracteres'] = sub_tabela_cod_pai_0['nome10caracteres'].str.replace('\\s+', '', regex=True)\n",
    "df_genealogia_abcz['nome10caracteres'] = sub_tabela_cod_pai_0['nome10caracteres'].str.replace('\\s+', '', regex=True)\n",
    "\n",
    "sub_tabela_cod_pai_0 = pd.merge(sub_tabela_cod_pai_0, df_genealogia_abcz[['RGVACA', 'cod_prod_pai_gen']], left_on=['RGPAI', 'nome10caracteres'], right_on=['RGVACA', 'nome10caracteres'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0.drop_duplicates()\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0.drop(sub_tabela_cod_pai_0.filter(regex='_drop$').columns, axis=1)\n",
    "sub_tabela_cod_pai_0 = sub_tabela_cod_pai_0[sub_tabela_cod_pai_0['_merge'] == 'both'].drop(columns='_merge')\n",
    "sub_tabela_cod_pai_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando o cod_prod_pai_gen dos pais no dataframe df_dados_novos\n",
    "obs: dos REGPAI que nao comecam com 3 caracteres"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_temporaria7 = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, sub_tabela_cod_pai_0[['RGPAI', 'cod_prod_pai_gen']], left_on=['RGPAI'], right_on=['RGPAI'], how='left', suffixes=('', '_drop'))\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados=df_temporaria5\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop_duplicates()\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop(df_dados_novos_para_insercao_no_banco_de_dados.filter(regex='_drop$').columns, axis=1)\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados\n",
    "df_temporaria7 = df_temporaria7.drop_duplicates()\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_temporaria7\n",
    "df_dados_novos_para_insercao_no_banco_de_dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criando subtabela em que o gs da mae = 11 mas os 3 primeiros caracteres do rgmae nao sao letras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_tabela_cod_mae_0 = df_dados_novos_para_insercao_no_banco_de_dados[df_dados_novos_para_insercao_no_banco_de_dados['GSMAE'] == 11]\n",
    "#e o cod_mae e nulo\n",
    "sub_tabela_cod_mae_0\n",
    "# selecionar apenas as linhas que NÃO começam com letras\n",
    "sub_tabela_cod_mae_0 = sub_tabela_cod_mae_0[~sub_tabela_cod_mae_0['nome'].apply(lambda x: bool(re.match(r'^[a-zA-Z]{3}', x)))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pegando cod_prod_mae no genealogia abcz dos animais em que o registro nao comeca com 3 letras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_genealogia_abcz = df_genealogia_abcz.rename(columns={'cod_prod_pai_gen':'cod_prod_mae_gen'})\n",
    "sub_tabela_cod_mae_0 = pd.merge(sub_tabela_cod_mae_0, df_genealogia_abcz[['RGVACA', 'cod_prod_mae_gen']], left_on=['RGMAE', 'nome10caracteres'], right_on=['RGVACA', 'nome10caracteres'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "sub_tabela_cod_mae_0 = sub_tabela_cod_mae_0.drop_duplicates()\n",
    "sub_tabela_cod_mae_0 = sub_tabela_cod_mae_0.drop(sub_tabela_cod_mae_0.filter(regex='_drop$').columns, axis=1)\n",
    "sub_tabela_cod_mae_0 = sub_tabela_cod_mae_0[sub_tabela_cod_mae_0['_merge'] == 'both'].drop(columns='_merge')\n",
    "sub_tabela_cod_mae_0\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando cod_prod_mae_gen no df_dados_novos\n",
    "Obs: maes com registro iniciando com menos de 3 caracteres"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_temporaria8 = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, sub_tabela_cod_pai_0[['RGMAE', 'cod_prod_mae_gen']], left_on=['RGMAE'], right_on=['RGMAE'], how='left', suffixes=('', '_drop'))\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados=df_temporaria5\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop_duplicates()\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop(df_dados_novos_para_insercao_no_banco_de_dados.filter(regex='_drop$').columns, axis=1)\n",
    "#df_dados_novos_para_insercao_no_banco_de_dados\n",
    "df_temporaria8 = df_temporaria8.drop_duplicates()\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_temporaria8\n",
    "df_dados_novos_para_insercao_no_banco_de_dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando reb no dataframe df_dados_novos_para_insercao_no_banco_de_dados\n",
    "Obs: Cod_gil esta na tabela de criadores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_criadores = df_criadores.rename(columns={'codgiro':'reb_giro'})\n",
    "\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, df_criadores[['reb_giro', 'reb']], on=['reb_giro'], how='left')\n",
    "df_dados_novos_para_insercao_no_banco_de_dados = df_dados_novos_para_insercao_no_banco_de_dados.drop_duplicates()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Pegando os dados das colunas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#verifica_reb = df_criadores.groupby('reb_giro')['reb'].nunique()\n",
    "#verifica_reb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculando a diferença entre a data dos novos partos com as ultimas datas presentes na tabela de dados_2022 para validar se ha alguma inconsistência\n",
    "\n",
    "obs: Caso a diferença seja menor que 250 dias é provável que haja alguma falha."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_diferenca_entre_partos_novos_e_do_banco = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, dados_2022, on=['IDANIMAL'], suffixes=('', '_drop'))\n",
    "df_diferenca_entre_partos_novos_e_do_banco = df_diferenca_entre_partos_novos_e_do_banco.drop_duplicates()\n",
    "#df_diferenca_entre_partos_novos_e_do_banco = df_diferenca_entre_partos_novos_e_do_banco.drop(df_diferenca_entre_partos_novos_e_do_banco.filter(regex='_drop$').columns, axis=1)\n",
    "df_diferenca_entre_partos_novos_e_do_banco[['parto', 'parto_drop']] = df_diferenca_entre_partos_novos_e_do_banco[['parto', 'parto_drop']].astype(str)\n",
    "df_diferenca_entre_partos_novos_e_do_banco[['parto', 'parto_drop']] = df_diferenca_entre_partos_novos_e_do_banco[['parto', 'parto_drop']].apply(pd.to_datetime)\n",
    "df_diferenca_entre_partos_novos_e_do_banco['diferenca_em_dias'] = (df_diferenca_entre_partos_novos_e_do_banco['parto'] - df_diferenca_entre_partos_novos_e_do_banco['parto_drop']).dt.days\n",
    "df_diferenca_entre_partos_novos_e_do_banco[['parto', 'parto_drop', 'diferenca_em_dias']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pegando da tabela de animais que serão inseridos no banco aqueles que ja possuem IDANIMAL cadastrado\n",
    "Comparado ao dataframe  dados_2022"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_com_ID = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, dados_2022, on =['IDANIMAL'], suffixes=('', '_drop'))\n",
    "df_animais_com_ID = df_animais_com_ID.drop(df_animais_com_ID.filter(regex='_drop$').columns, axis=1)\n",
    "df_animais_com_ID = df_animais_com_ID.drop_duplicates()\n",
    "df_animais_com_ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pegando da tabela de animais que serão inseridos no banco, todos aqueles que não possuem IDANIMAL cadastrado\n",
    "comparado ao dataframe dados_2022"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_sem_id = pd.merge(df_dados_novos_para_insercao_no_banco_de_dados, dados_2022, on='IDANIMAL', how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_sem_id = df_animais_sem_id.drop(df_animais_sem_id.filter(regex='_drop$').columns, axis=1)\n",
    "df_animais_sem_id = df_animais_sem_id[df_animais_sem_id['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "df_animais_sem_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dados_2022[dados_2022['IDANIMAL'] == 1631099]\n",
    "#df_verificando_animais_com_id_na_genealogia_embrapa['IDANIMAL'].value_counts()\n",
    "#verifica_reb = df_verificando_animais_com_id_na_genealogia_embrapa.groupby('IDANIMAL')['id_produto'].nunique()\n",
    "#verifica_reb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionando a coluna id_produto ao dataframe df_animais_com_ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_genealogia_embrapa['IDANIMAL'] = df_genealogia_embrapa['IDANIMAL'].astype('int')\n",
    "df_animais_com_ID = pd.merge(df_animais_com_ID, df_genealogia_embrapa[['IDANIMAL', 'id_produto']], on='IDANIMAL', how='left', indicator=True)\n",
    "df_animais_com_ID = df_animais_com_ID.drop_duplicates()\n",
    "df_animais_com_ID = df_animais_com_ID.drop(columns='_merge')\n",
    "df_animais_com_ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lista de animais do dataframe sem ID em relacao a dados_2022 e que possuem ID_animal no dataframe da genealogia_Embrapa\n",
    "Obs: Tem que ter ID_produto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_sem_id = df_animais_sem_id.add_suffix('_esq')\n",
    "df_genealogia_embrapa = df_genealogia_embrapa.add_suffix('_dir')\n",
    "\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco = pd.merge(df_animais_sem_id, df_genealogia_embrapa, left_on=['IDANIMAL_esq'], right_on=['IDANIMAL_dir'], how='left', indicator=True)\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco.drop_duplicates()\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco = df_animais_sem_id_2022_que_possuem_id_no_banco.drop(df_animais_sem_id_2022_que_possuem_id_no_banco.filter(regex='_drop$').columns, axis=1)\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco = df_animais_sem_id_2022_que_possuem_id_no_banco[df_animais_sem_id_2022_que_possuem_id_no_banco['_merge'] == 'both']\n",
    "\n",
    "# dropa as colunas que não são necessárias\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco = df_animais_sem_id_2022_que_possuem_id_no_banco.drop(df_animais_sem_id_2022_que_possuem_id_no_banco.filter(regex='_dir').columns.difference(['id_produto_dir']), axis=1)\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco = df_animais_sem_id_2022_que_possuem_id_no_banco.rename(columns=lambda x: x.replace('_esq', '') if '_esq' in x else x)\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco = df_animais_sem_id_2022_que_possuem_id_no_banco.rename(columns=lambda x: x.replace('_dir', '') if '_dir' in x else x)\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco.drop(columns='_merge')\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco = df_animais_sem_id_2022_que_possuem_id_no_banco.drop(columns='_merge')\n",
    "df_animais_sem_id_2022_que_possuem_id_no_banco"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criando dataframe com todos os animais que possuem ID encontrado"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Juntando os dataframes\n",
    "df_animais_com_ID = pd.concat([df_animais_com_ID, df_animais_sem_id_2022_que_possuem_id_no_banco])\n",
    "df_animais_com_ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Atualizando lista de animais sem ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Tirando o sufixo da tabela\n",
    "df_animais_sem_id = df_animais_sem_id.rename(columns=lambda x: x.replace('_esq', '') if '_esq' in x else x)\n",
    "# Imprimir o resultado\n",
    "df_animais_sem_id = pd.merge(df_animais_sem_id, df_animais_com_ID, on=['IDANIMAL'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_sem_id = df_animais_sem_id.drop(df_animais_sem_id.filter(regex='_drop$').columns, axis=1)\n",
    "# Seleciona apenas as linhas que possuem valores nulos na coluna \"id_produto\"\n",
    "df_animais_sem_id = df_animais_sem_id[df_animais_sem_id['id_produto'].isnull()]\n",
    "df_animais_sem_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fazendo busca no dataframe producao para encontrar id_produto dos animais sem id\n",
    "conferir manualmente se entram ou não no banco"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Criando coluna com o ano de parto e mes parto no dataframe df_producao\n",
    "df_producao['parto'] = df_producao['parto'].astype(str)\n",
    "df_producao['AP'] = df_producao['parto'].str.slice(start=0, stop=4)\n",
    "df_producao['MP'] = df_producao['parto'].str.slice(start=5, stop=7)\n",
    "#Pegando os 10 primeiros caracteres de nome dos dataframes aniamis sem id e producao\n",
    "df_producao['nome10caracteres'] = df_producao['nome'].str.slice(start=0, stop=11)\n",
    "df_animais_sem_id['nome10caracteres'] = df_animais_sem_id['nomea'].str.slice(start=0, stop=11)\n",
    "#removendo os espacos em branco das celulas\n",
    "df_producao['nome10caracteres'] = df_producao['nome10caracteres'].str.replace('\\s+', '', regex=True)\n",
    "df_animais_sem_id['nome10caracteres'] = df_animais_sem_id['nome10caracteres'].str.replace('\\s+', '', regex=True)\n",
    "\n",
    "df_animais_sem_id = df_animais_sem_id.drop(df_animais_sem_id.filter(regex='_drop$').columns, axis=1)\n",
    "df_producao = df_producao.drop(df_producao.filter(regex='_drop$').columns, axis=1)\n",
    "df_animais_sem_id = df_animais_sem_id.drop(columns='_merge')\n",
    "\n",
    "df_producao['AP'] = df_producao['AP'].astype(int)\n",
    "df_producao['MP'] = df_producao['MP'].astype(int)\n",
    "df_animais_sem_id['AP'] = df_animais_sem_id['AP'].astype(int)\n",
    "df_animais_sem_id['MP'] = df_animais_sem_id['MP'].astype(int)\n",
    "df_animais_com_id_na_producao = pd.merge(df_animais_sem_id, df_producao[['reb','AP', 'MP', 'nome10caracteres','id_produto']], on=['reb', 'AP', 'MP', 'nome10caracteres'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_com_id_na_producao = df_animais_com_id_na_producao[df_animais_com_id_na_producao['_merge'] == 'both']\n",
    "df_animais_com_id_na_producao = df_animais_com_id_na_producao.drop(columns={'_merge', 'id_produto'})\n",
    "df_animais_com_id_na_producao = df_animais_com_id_na_producao.rename(columns={'id_produto_drop': 'id_produto'})\n",
    "df_animais_com_id_na_producao"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Atualizando animais com id com os novos ids_produtos encontrados no dataframe de producao"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_com_ID = pd.concat([df_animais_com_ID, df_animais_com_id_na_producao])\n",
    "df_animais_com_ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Atualizando lista de animais sem id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_sem_id = pd.merge(df_animais_sem_id, df_animais_com_ID, on=['IDANIMAL'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_sem_id = df_animais_sem_id[df_animais_sem_id['id_produto_drop'].isnull()]\n",
    "df_animais_sem_id = df_animais_sem_id.drop(df_animais_sem_id.filter(regex='_drop$').columns, axis=1)\n",
    "# Seleciona apenas as linhas que possuem valores nulos na coluna \"id_produto\"\n",
    "df_animais_sem_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fazendo a busca na tabela genealogia_embrapa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Retirando sufixo tabela genealogia\n",
    "df_genealogia_embrapa = df_genealogia_embrapa.rename(columns=lambda x: x.replace('_dir', '') if '_dir' in x else x)\n",
    "#Pegando ano nascimento nas colunas\n",
    "df_genealogia_embrapa['nasc_est'] = df_genealogia_embrapa['nasc_est'].astype(str)\n",
    "df_genealogia_embrapa['AN'] = df_genealogia_embrapa['nasc_est'].str.slice(start=0, stop=4)\n",
    "df_animais_sem_id['nasc'] = df_animais_sem_id['nasc'].astype(str)\n",
    "df_animais_sem_id['AN'] = df_animais_sem_id['nasc'].str.slice(start=0, stop=4)\n",
    "#Criando coluna com os 10 caracteres do nome na genealogia_embrapa\n",
    "df_genealogia_embrapa['nome10caracteres'] = df_genealogia_embrapa['nome'].str.slice(start=0, stop=11)\n",
    "#Convertendo coluna ano e mes para tipo inteiro\n",
    "#df_genealogia_embrapa['AN'] = df_genealogia_embrapa['AN'].astype(int)\n",
    "#Limpando tabelas\n",
    "df_animais_sem_id = df_animais_sem_id.drop(df_animais_sem_id.filter(regex='_drop$').columns, axis=1)\n",
    "df_genealogia_embrapa = df_genealogia_embrapa.drop(df_genealogia_embrapa.filter(regex='_drop$').columns, axis=1)\n",
    "df_animais_sem_id = df_animais_sem_id.drop(columns={'_merge'})\n",
    "#criando dataframe com os ids_encontrados\n",
    "df_animais_com_id_na_genealogia = pd.merge(df_animais_sem_id, df_genealogia_embrapa[['nome10caracteres','gs', 'registro_mae', 'registro_pai', 'sexo', 'AN','id_produto']], left_on=['nome10caracteres', 'gs','RGMAE', 'RGPAI', 'sexo', 'AN'], right_on=['nome10caracteres','gs', 'registro_mae', 'registro_pai', 'sexo', 'AN'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_com_id_na_genealogia = df_animais_com_id_na_genealogia[df_animais_com_id_na_genealogia['_merge'] == 'both']\n",
    "df_animais_com_id_na_genealogia = df_animais_com_id_na_genealogia.drop(columns={'_merge', 'id_produto', 'registro_mae', 'registro_pai'})\n",
    "df_animais_com_id_na_genealogia = df_animais_com_id_na_genealogia.rename(columns={'id_produto_drop': 'id_produto'})\n",
    "df_animais_com_id_na_genealogia = df_animais_com_id_na_genealogia.drop(df_animais_com_id_na_genealogia.filter(regex='_drop$').columns, axis=1)\n",
    "df_animais_com_id_na_genealogia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Conferência manual dos matchs com o dataframe da genealogia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_com_id_na_genealogia1 = pd.merge(df_animais_sem_id, df_genealogia_embrapa[['nome10caracteres','gs', 'registro_pai', 'sexo', 'AN','id_produto']], left_on=['nome10caracteres', 'gs', 'RGPAI', 'sexo', 'AN'], right_on=['nome10caracteres','gs', 'registro_pai', 'sexo', 'AN'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_com_id_na_genealogia1 = df_animais_com_id_na_genealogia1[df_animais_com_id_na_genealogia1['_merge'] == 'both']\n",
    "df_animais_com_id_na_genealogia1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adicionar o que ta escrito no quadro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_com_id_na_genealogia1 = pd.merge(df_animais_sem_id, df_genealogia_embrapa[['nome10caracteres','gs', 'sexo', 'AN','id_produto']], left_on=['nome10caracteres', 'gs', 'sexo', 'AN'], right_on=['nome10caracteres','gs', 'sexo', 'AN'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_com_id_na_genealogia1 = df_animais_com_id_na_genealogia1[df_animais_com_id_na_genealogia1['_merge'] == 'both']\n",
    "df_animais_com_id_na_genealogia1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_animais_com_id_na_genealogia2 = pd.merge(df_animais_sem_id, df_genealogia_embrapa[['id_produto','cod_prod']], left_on=['cod_prod'], right_on=['cod_prod'], how='left', indicator=True, suffixes=('', '_drop'))\n",
    "df_animais_com_id_na_genealogia2 = df_animais_com_id_na_genealogia2[df_animais_com_id_na_genealogia2['_merge'] == 'both']\n",
    "df_animais_com_id_na_genealogia2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
